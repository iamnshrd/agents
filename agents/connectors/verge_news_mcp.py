#!/usr/bin/env python3
"""
MCP –∫–ª–∏–µ–Ω—Ç –¥–ª—è The Verge News
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Smithery –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ verge-news-mcp —Å–µ—Ä–≤–µ—Ä—É
"""

import os
import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import json

logger = logging.getLogger(__name__)

class VergeNewsMCPClient:
    """
    MCP –∫–ª–∏–µ–Ω—Ç –¥–ª—è The Verge News
    """
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("SMITHERY_API_KEY", "970828f0-e3a7-4778-a72f-2cc44656511d")
        self.base_url = "https://server.smithery.ai/@manimohans/verge-news-mcp/mcp"
        self._session = None
        # retry params
        try:
            self.retry_attempts = int(os.getenv("SMITHERY_RETRY_ATTEMPTS", "3"))
        except Exception:
            self.retry_attempts = 3
        try:
            self.retry_backoff = float(os.getenv("SMITHERY_RETRY_BACKOFF_SECS", "1.5"))
        except Exception:
            self.retry_backoff = 1.5
        
    async def _get_session(self):
        """–ü–æ–ª—É—á–∞–µ—Ç MCP —Å–µ—Å—Å–∏—é"""
        try:
            from mcp import ClientSession
            from mcp.client.streamable_http import streamablehttp_client
            from urllib.parse import urlencode
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL —Å –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
            params = {"api_key": self.api_key}
            url = f"{self.base_url}?{urlencode(params)}"
            
            # –†–µ—Ç—Ä–∞–∏–º —É—Å—Ç–∞–Ω–æ–≤–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            last_err = None
            for attempt in range(1, self.retry_attempts + 1):
                try:
                    client = streamablehttp_client(url)
                    read, write, _ = await client.__aenter__()
                    session = ClientSession(read, write)
                    await session.__aenter__()
                    await session.initialize()
                    return session, client
                except Exception as e:
                    last_err = e
                    logger.warning(
                        f"MCP session connect failed (attempt {attempt}/{self.retry_attempts}): {e}"
                    )
                    # simple backoff
                    await asyncio.sleep(self.retry_backoff * attempt)
            logger.error(f"Failed to create MCP session after retries: {last_err}")
            return None, None
            
        except Exception as e:
            logger.error(f"Error creating MCP session: {e}")
            return None, None
    
    async def get_daily_news(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            session, client = await self._get_session()
            if not session:
                return self._fallback_daily_news()
            
            try:
                # –í—ã–∑—ã–≤–∞–µ–º get-daily-news
                result = await session.call_tool("get-daily-news", {})
                
                if result.content:
                    parsed_items = self._parse_tool_content(result.content)
                    news_items: List[Dict[str, Any]] = []
                    for item in parsed_items:
                        news_items.append({
                            "title": item.get("title", "No title"),
                            "description": item.get("description", item.get("summary", "No description")),
                            "url": item.get("url", item.get("link", "")),
                            "published_at": item.get("published_at", item.get("publishedAt", item.get("pubDate", ""))),
                            "source": item.get("source", "The Verge"),
                            "relevance_score": float(item.get("relevance_score", 0.9)),
                            "category": item.get("category", "Technology News")
                        })
                    logger.info(f"Retrieved {len(news_items)} daily news items from The Verge")
                    return news_items
                else:
                    logger.warning("No content in daily news response")
                    return self._fallback_daily_news()
                    
            finally:
                await session.__aexit__(None, None, None)
                await client.__aexit__(None, None, None)
                
        except Exception as e:
            logger.error(f"Error getting daily news: {e}")
            return self._fallback_daily_news()
    
    async def get_weekly_news(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            session, client = await self._get_session()
            if not session:
                return self._fallback_weekly_news()
            
            try:
                # –í—ã–∑—ã–≤–∞–µ–º get-weekly-news
                result = await session.call_tool("get-weekly-news", {})
                
                if result.content:
                    parsed_items = self._parse_tool_content(result.content)
                    news_items: List[Dict[str, Any]] = []
                    for item in parsed_items:
                        news_items.append({
                            "title": item.get("title", "No title"),
                            "description": item.get("description", item.get("summary", "No description")),
                            "url": item.get("url", item.get("link", "")),
                            "published_at": item.get("published_at", item.get("publishedAt", item.get("pubDate", ""))),
                            "source": item.get("source", "The Verge"),
                            "relevance_score": float(item.get("relevance_score", 0.8)),
                            "category": item.get("category", "Technology News")
                        })
                    logger.info(f"Retrieved {len(news_items)} weekly news items from The Verge")
                    return news_items
                else:
                    logger.warning("No content in weekly news response")
                    return self._fallback_weekly_news()
                    
            finally:
                await session.__aexit__(None, None, None)
                await client.__aexit__(None, None, None)
                
        except Exception as e:
            logger.error(f"Error getting weekly news: {e}")
            return self._fallback_weekly_news()
    
    async def search_news(self, keyword: str, days_back: int = 30) -> List[Dict[str, Any]]:
        """
        –ò—â–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É
        
        Args:
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            days_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            session, client = await self._get_session()
            if not session:
                return self._fallback_search_news(keyword)
            
            try:
                # –í—ã–∑—ã–≤–∞–µ–º search-news
                result = await session.call_tool("search-news", {
                    "keyword": keyword,
                    "days": days_back
                })
                
                if result.content:
                    parsed_items = self._parse_tool_content(result.content)
                    news_items: List[Dict[str, Any]] = []
                    for item in parsed_items:
                        news_items.append({
                            "title": item.get("title", "No title"),
                            "description": item.get("description", item.get("summary", "No description")),
                            "url": item.get("url", item.get("link", "")),
                            "published_at": item.get("published_at", item.get("publishedAt", item.get("pubDate", ""))),
                            "source": item.get("source", "The Verge"),
                            "relevance_score": float(item.get("relevance_score", 0.85)),
                            "category": item.get("category", "Technology News"),
                            "search_keyword": keyword
                        })
                    logger.info(f"Found {len(news_items)} news items for keyword '{keyword}'")
                    return news_items
                else:
                    logger.warning(f"No content in search response for keyword '{keyword}'")
                    return self._fallback_search_news(keyword)
                    
            finally:
                await session.__aexit__(None, None, None)
                await client.__aexit__(None, None, None)
                
        except Exception as e:
            logger.error(f"Error searching news for '{keyword}': {e}")
            return self._fallback_search_news(keyword)

    def _parse_tool_content(self, content_items: List[Any]) -> List[Dict[str, Any]]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ MCP-–æ—Ç–≤–µ—Ç–∞ (TextContent/JSON/—Å–ª–æ–≤–∞—Ä—å).
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –Ω–æ–≤–æ—Å—Ç–µ–π.
        """
        parsed: List[Dict[str, Any]] = []
        for item in content_items:
            try:
                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                if isinstance(item, dict):
                    parsed.append(item)
                    continue
                # –ï—Å–ª–∏ —É —ç–ª–µ–º–µ–Ω—Ç–∞ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
                text = None
                if hasattr(item, "text") and isinstance(item.text, str):
                    text = item.text
                elif hasattr(item, "value") and isinstance(item.value, str):
                    text = item.value
                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –µ—Å–ª–∏ —ç—Ç–æ —Ç–µ–∫—Å—Ç
                if text is not None:
                    try:
                        data = json.loads(text)
                        if isinstance(data, list):
                            for d in data:
                                if isinstance(d, dict):
                                    parsed.append(d)
                                else:
                                    parsed.append({"description": str(d)})
                        elif isinstance(data, dict):
                            parsed.append(data)
                        else:
                            parsed.append({"description": str(data)})
                    except Exception:
                        # –¢–µ–∫—Å—Ç –±–µ–∑ JSON ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏–µ
                        parsed.append({"description": text})
                else:
                    # –§–æ–ª–ª–±–µ–∫: –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
                    parsed.append({"description": str(item)})
            except Exception as e:
                logger.warning(f"Failed to parse tool content item: {e}")
        return parsed
    
    async def get_available_tools(self) -> List[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        """
        try:
            session, client = await self._get_session()
            if not session:
                return ["get-daily-news", "get-weekly-news", "search-news"]
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
                tools_result = await session.list_tools()
                tool_names = [tool.name for tool in tools_result.tools]
                
                logger.info(f"Available tools: {', '.join(tool_names)}")
                return tool_names
                
            finally:
                await session.__aexit__(None, None, None)
                await client.__aexit__(None, None, None)
                
        except Exception as e:
            logger.error(f"Error getting available tools: {e}")
            return ["get-daily-news", "get-weekly-news", "search-news"]
    
    def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ MCP —Å–µ—Ä–≤–µ—Ä–∞
        
        Returns:
            –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            loop = asyncio.new_event_loop()
            try:
                tools = loop.run_until_complete(self.get_available_tools())
                return {
                    "status": "healthy",
                    "available_tools": tools,
                    "api_key_configured": bool(self.api_key),
                    "timestamp": datetime.now().isoformat(),
                    "source": "verge-news-mcp"
                }
            finally:
                loop.close()
                
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "api_key_configured": bool(self.api_key),
                "timestamp": datetime.now().isoformat(),
                "source": "verge-news-mcp"
            }
    
    def _fallback_daily_news(self) -> List[Dict[str, Any]]:
        """Fallback –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –¥–µ–Ω—å"""
        return [
            {
                "title": "The Verge: Latest Technology News",
                "description": "Fallback daily news from The Verge",
                "url": "https://www.theverge.com",
                "published_at": datetime.now().isoformat(),
                "source": "The Verge (Fallback)",
                "relevance_score": 0.7,
                "category": "Technology News"
            }
        ]
    
    def _fallback_weekly_news(self) -> List[Dict[str, Any]]:
        """Fallback –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –Ω–µ–¥–µ–ª—é"""
        return [
            {
                "title": "The Verge: Weekly Technology Roundup",
                "description": "Fallback weekly news from The Verge",
                "url": "https://www.theverge.com",
                "published_at": (datetime.now() - timedelta(days=3)).isoformat(),
                "source": "The Verge (Fallback)",
                "relevance_score": 0.6,
                "category": "Technology News"
            }
        ]
    
    def _fallback_search_news(self, keyword: str) -> List[Dict[str, Any]]:
        """Fallback –ø–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        return [
            {
                "title": f"The Verge: News about {keyword}",
                "description": f"Fallback search results for '{keyword}' from The Verge",
                "url": "https://www.theverge.com",
                "published_at": datetime.now().isoformat(),
                "source": "The Verge (Fallback)",
                "relevance_score": 0.5,
                "category": "Technology News",
                "search_keyword": keyword
            }
        ]

# –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞
class VergeNewsMCPSync:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è VergeNewsMCPClient"""
    
    def __init__(self, api_key: str = None):
        self.client = VergeNewsMCPClient(api_key)
    
    def get_daily_news(self) -> List[Dict[str, Any]]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        loop = asyncio.new_event_loop()
        try:
            return loop.run_until_complete(self.client.get_daily_news())
        finally:
            loop.close()
    
    def get_weekly_news(self) -> List[Dict[str, Any]]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–¥–µ–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        loop = asyncio.new_event_loop()
        try:
            return loop.run_until_complete(self.client.get_weekly_news())
        finally:
            loop.close()
    
    def search_news(self, keyword: str, days_back: int = 30) -> List[Dict[str, Any]]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        loop = asyncio.new_event_loop()
        try:
            return loop.run_until_complete(self.client.search_news(keyword, days_back))
        finally:
            loop.close()
    
    def get_available_tools(self) -> List[str]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        loop = asyncio.new_event_loop()
        try:
            return loop.run_until_complete(self.client.get_available_tools())
        finally:
            loop.close()
    
    def health_check(self) -> Dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        return self.client.health_check()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
verge_news_client = VergeNewsMCPClient()

if __name__ == "__main__":
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MCP –∫–ª–∏–µ–Ω—Ç–∞"""
    async def test_client():
        client = VergeNewsMCPClient()
        
        print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã...")
        tools = await client.get_available_tools()
        print(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {', '.join(tools)}")
        
        print("\nüì∞ –ü–æ–ª—É—á–∞–µ–º –¥–Ω–µ–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏...")
        daily_news = await client.get_daily_news()
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(daily_news)} –¥–Ω–µ–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        print("\nüîç –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –æ–± AI...")
        ai_news = await client.search_news("AI", 7)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(ai_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –æ–± AI")
        
        print("\nüìä –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ...")
        health = client.health_check()
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å: {health['status']}")
    
    try:
        asyncio.run(test_client())
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
